{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f19125be-4634-4de8-a40f-59c098552eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from face_recog import Face_recog\n",
    "from imutils import face_utils\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import dlib\n",
    "from headpose import head_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf4e6ab-10ca-494b-ad81-6b7d9db7e70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_fps(frame):\n",
    "    global pTime\n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime - pTime)\n",
    "    pTime = cTime\n",
    "    cv2.putText(frame, f\"FPS: {int(fps)}\", (60, 70), font, 3, (0,255,0), 2)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8161a25-4308-4d50-875e-9f119291346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(frame, draw = True, score= False):\n",
    "    \"\"\"\n",
    "    Outputs the image of detected face and alert_bool\n",
    "    \"\"\"\n",
    "    global noface_count\n",
    "    global multiple_faces_count\n",
    "    alert_bool = False\n",
    "    bbox_ret = []\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    \n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detector:\n",
    "        \n",
    "        # To improve performance, optionally mark the frame as not writeable to\n",
    "        # pass by reference.\n",
    "        frame.flags.writeable = False\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        #Face detection:\n",
    "        results = face_detector.process(frame)\n",
    "        frame.flags.writeable = True\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "    # Absence of any face detection\n",
    "    if not results.detections:\n",
    "        noface_count+=1\n",
    "        alert_bool = True\n",
    "        cv2.putText(frame, 'Alert! No faces detected for '+str(noface_count)+' times', (30, 30), font, 1, (0, 255, 255), 2)\n",
    "    # Multiple faces detection\n",
    "    elif len(results.detections)>1:\n",
    "        multiple_faces_count += 1\n",
    "        alert_bool = True\n",
    "        cv2.putText(frame, 'Alert! multiple faces detected for '+str(multiple_faces_count)+' times', (30, 30), font, 1, (0, 255, 255), 2)\n",
    "    else:\n",
    "        # bbox return for the single face:\n",
    "        for id, detection in enumerate(results.detections):\n",
    "            bbox_ret = detection.location_data.relative_bounding_box\n",
    "            ih, iw, ic = frame.shape\n",
    "            bbox_ret = int(bbox_ret.xmin * iw), int(bbox_ret.ymin * ih), int(bbox_ret.width * iw), int(bbox_ret.height * ih)\n",
    "            \n",
    "    # Draw the face detection annotations on the frame.\n",
    "        if draw:\n",
    "            if results.detections:\n",
    "                for id, detection in enumerate(results.detections):\n",
    "                    bboxC = detection.location_data.relative_bounding_box\n",
    "                    ih, iw, ic = frame.shape\n",
    "                    bbox = int(bboxC.xmin * iw), int(bboxC.ymin * ih), int(bboxC.width * iw), int(bboxC.height * ih)\n",
    "                    cv2.rectangle(frame, bbox, (255, 0, 255), 2)\n",
    "                    if score:\n",
    "                        cv2.putText(frame, f'{int(detection.score[0] * 100)}%', (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return alert_bool, frame, bbox_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53784fc0-8427-4b53-82b2-314268a17951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(frame, fr, bbox):\n",
    "    global failed_verif_count\n",
    "    \n",
    "    # Detect and recognise Faces\n",
    "    face_locations, face_names = fr.detect_known_faces(frame)\n",
    "    \n",
    "    #Draw box and name\n",
    "    for face_loc, name in zip(face_locations, face_names):\n",
    "        cv2.putText(frame, name, (bbox[0], bbox[1] - 20), cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 255), 2)\n",
    "        \n",
    "\n",
    "    alert_bool = not face_names\n",
    "    if not alert_bool:\n",
    "        cv2.putText(frame, 'You are verified', (30, 30), font, 1, (0, 255, 255), 2)\n",
    "    else:\n",
    "        failed_verif_count += 1\n",
    "        cv2.putText(frame, 'Alert! You are not the actual user: '+str(failed_verif_count), (30, 30), font, 1, (0, 255, 255), 2)\n",
    "        \n",
    "    return alert_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a30e28-12da-4d9e-93e8-e7b35e6d34f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facial_landmarks_detection(frame, draw= True):\n",
    "    # detect faces in the grayscale image\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)   \n",
    "    rects = detector(gray, 0)\n",
    "    shape = \"\"\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "        # loop over the (x, y)-coordinates for the facial landmarks\n",
    "        # and draw them on the frame\n",
    "        if draw:\n",
    "            for (x, y) in shape:\n",
    "                cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
    "    return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47386dbb-e78e-486e-bf7a-87f97cec1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 encoding images found.\n",
      "Encoding images loaded\n"
     ]
    }
   ],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "while True:\n",
    "    blank = cv2.imread('db/blank.png')\n",
    "    cv2.putText(blank, 'press r to capture image', (30, 30), font, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Output\", blank)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('r'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# capturing image\n",
    "webcam = cv2.VideoCapture(0) \n",
    "ret, frame = webcam.read()\n",
    "# saving image as use_image.jpg\n",
    "# for further face verification\n",
    "cv2.imwrite(\"captures/user_image.jpg\", frame)\n",
    "webcam.release()\n",
    "cv2.destroyAllWindows()\n",
    "user_pic = cv2.imread('captures/user_image.jpg')\n",
    "# reading picture as user_pic\n",
    "\n",
    "# Face recognizer\n",
    "fr = Face_recog()\n",
    "fr.load_encoding_images(\"captures/\")\n",
    "\n",
    "# Facial landmarks predictor\n",
    "saved_model = \"models/shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(saved_model)\n",
    "\n",
    "noface_count = 0\n",
    "multiple_faces_count = 0\n",
    "failed_verif_count = 0\n",
    "pTime = 0\n",
    "font = cv2.FONT_HERSHEY_PLAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f0c9c75-3f07-4e8a-86f2-dfcf57003453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        # Video capture frame by frame\n",
    "        ret, frame = cap.read()\n",
    "        shape = 1\n",
    "        \n",
    "        #Faces detection\n",
    "        alert_bool, frame, bbox =  face_detection(frame)\n",
    "        \n",
    "        #Only if single face detected\n",
    "        if not alert_bool:    \n",
    "            \n",
    "            #Face verification\n",
    "            # alert_bool = face_recognition(frame, fr, bbox)\n",
    "            \n",
    "            #Only if face is verified\n",
    "            if not alert_bool:   \n",
    "                \n",
    "                # Facial landmarks detection\n",
    "                shape = facial_landmarks_detection(frame)\n",
    "                print(shape)\n",
    "                head_main(frame,shape)\n",
    "        cv2.imshow('PROCTORING ON', print_fps(frame) ) #cv2.flip(frame, 1)\n",
    "                \n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58be2877-3649-451a-8414-56e1648ce587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[268 304]\n",
      " [268 319]\n",
      " [269 333]\n",
      " [271 348]\n",
      " [277 362]\n",
      " [285 374]\n",
      " [297 382]\n",
      " [312 387]\n",
      " [328 388]\n",
      " [344 385]\n",
      " [358 379]\n",
      " [370 369]\n",
      " [379 358]\n",
      " [385 343]\n",
      " [386 328]\n",
      " [385 313]\n",
      " [384 298]\n",
      " [277 289]\n",
      " [282 281]\n",
      " [291 277]\n",
      " [301 277]\n",
      " [310 279]\n",
      " [330 277]\n",
      " [340 274]\n",
      " [351 274]\n",
      " [361 278]\n",
      " [368 285]\n",
      " [321 293]\n",
      " [322 301]\n",
      " [322 309]\n",
      " [322 317]\n",
      " [311 327]\n",
      " [317 328]\n",
      " [323 330]\n",
      " [329 328]\n",
      " [335 326]\n",
      " [287 297]\n",
      " [293 291]\n",
      " [301 291]\n",
      " [308 297]\n",
      " [301 299]\n",
      " [293 299]\n",
      " [336 296]\n",
      " [343 289]\n",
      " [351 289]\n",
      " [357 295]\n",
      " [352 297]\n",
      " [344 297]\n",
      " [302 354]\n",
      " [309 345]\n",
      " [318 341]\n",
      " [324 343]\n",
      " [330 341]\n",
      " [338 344]\n",
      " [346 352]\n",
      " [339 358]\n",
      " [331 361]\n",
      " [325 361]\n",
      " [318 362]\n",
      " [309 360]\n",
      " [305 353]\n",
      " [318 348]\n",
      " [324 348]\n",
      " [330 348]\n",
      " [342 351]\n",
      " [331 353]\n",
      " [324 354]\n",
      " [318 354]]\n",
      "[[267 311]\n",
      " [267 324]\n",
      " [267 337]\n",
      " [270 351]\n",
      " [273 365]\n",
      " [277 378]\n",
      " [284 391]\n",
      " [293 401]\n",
      " [308 403]\n",
      " [325 401]\n",
      " [342 393]\n",
      " [357 381]\n",
      " [368 369]\n",
      " [376 353]\n",
      " [379 336]\n",
      " [379 317]\n",
      " [380 298]\n",
      " [260 302]\n",
      " [264 295]\n",
      " [272 294]\n",
      " [280 295]\n",
      " [289 298]\n",
      " [308 295]\n",
      " [320 290]\n",
      " [332 288]\n",
      " [345 288]\n",
      " [355 296]\n",
      " [298 311]\n",
      " [296 320]\n",
      " [294 328]\n",
      " [292 337]\n",
      " [286 345]\n",
      " [291 347]\n",
      " [297 349]\n",
      " [304 346]\n",
      " [312 344]\n",
      " [269 313]\n",
      " [274 307]\n",
      " [282 307]\n",
      " [289 313]\n",
      " [282 316]\n",
      " [274 316]\n",
      " [320 310]\n",
      " [326 303]\n",
      " [335 302]\n",
      " [343 306]\n",
      " [336 311]\n",
      " [327 312]\n",
      " [282 368]\n",
      " [287 362]\n",
      " [293 360]\n",
      " [300 361]\n",
      " [306 359]\n",
      " [317 361]\n",
      " [330 365]\n",
      " [319 376]\n",
      " [309 380]\n",
      " [302 381]\n",
      " [295 381]\n",
      " [288 377]\n",
      " [286 368]\n",
      " [294 366]\n",
      " [300 367]\n",
      " [307 366]\n",
      " [325 365]\n",
      " [307 371]\n",
      " [301 372]\n",
      " [294 371]]\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KATHUR~1\\AppData\\Local\\Temp/ipykernel_4152/5576575.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KATHUR~1\\AppData\\Local\\Temp/ipykernel_4152/1240230209.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfacial_landmarks_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mhead_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PROCTORING ON'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_fps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#cv2.flip(frame, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\mini_project_iiita\\headpose.py\u001b[0m in \u001b[0;36mhead_main\u001b[1;34m(img, marks)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# mark_detector.draw_marks(img, marks, color=(0, 255, 0))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         image_points = np.array([\n\u001b[1;32m---> 96\u001b[1;33m                                 \u001b[0mmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# Nose tip\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m                                 \u001b[0mmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# Chin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                 \u001b[0mmarks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m     \u001b[1;31m# Left eye left corner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
